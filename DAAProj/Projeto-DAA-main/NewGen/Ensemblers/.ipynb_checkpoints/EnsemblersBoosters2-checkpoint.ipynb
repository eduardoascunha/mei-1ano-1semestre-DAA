{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85d5af3c-b360-40ac-b1ca-b040430bede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import imblearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "513583d0-7bfc-47db-8c03-0bea800b7004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    random.seed(seed) # Python\n",
    "    np.random.seed(seed)  # Numpy, é o gerador utilizado pelo sklearn\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)  # sistema operativo\n",
    "\n",
    "set_seed(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4957abd-3351-470e-b871-78b5eec613fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "radi = pd.read_csv(\"../prep2/train_full_prep2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "764516de-dd90-4e8f-8d0a-e508e0b9dfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV,StratifiedKFold,cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "# Estado vai ser comum para todos os modelos, \n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e07871-dd1b-489a-aae5-ee509069e8f1",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27898429-69f0-4ccd-a29f-e9005376da27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RandomForest Model Parameters: {'n_estimators': 100}\n",
      "0.327265027024849\n"
     ]
    }
   ],
   "source": [
    "# Split data into features and target\n",
    "df = radi.copy()\n",
    "X = df.drop(columns=[\"Transition\"])\n",
    "y = df[\"Transition\"]\n",
    "\n",
    "bagging_params = {\"n_estimators\": [100]}\n",
    "bagging_model = BaggingClassifier(random_state=2025)\n",
    "bagging_grid = GridSearchCV(bagging_model, bagging_params, scoring='f1_macro', cv=skf, n_jobs=-1)\n",
    "bagging_grid.fit(X, y)\n",
    "print(f\"Best RandomForest Model Parameters: {bagging_grid.best_params_}\")\n",
    "f1_scores = cross_val_score(bagging_grid.best_estimator_,X,y,cv=skf,scoring=\"f1_macro\")\n",
    "print(f1_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18a4150-9b94-4422-b7e4-cf77d7f24380",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b65dbbe1-66b1-467a-bc3f-dd06e38be801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RandomForest Model Parameters: {'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'n_estimators': 300}\n",
      "0.33658911681204573\n"
     ]
    }
   ],
   "source": [
    "# Split data into features and target\n",
    "df = radi.copy()\n",
    "X = df.drop(columns=[\"Transition\"])\n",
    "y = df[\"Transition\"]\n",
    "\n",
    "# Params Definition\n",
    "\"\"\"\n",
    "rf_params = {\"n_estimators\": [100,300,500],\n",
    "             \"max_depth\": [5, 10, 20, None],\n",
    "             \"criterion\" :[\"gini\",\"entropy\"],\n",
    "             \"max_features\":[\"sqrt\",\"log2\", None]     \n",
    "             }\n",
    "\n",
    "\n",
    "             \"100\" !\n",
    "             \"5\"   !\n",
    "             \"entropy\" !\n",
    "             \"log2\" !\n",
    "\"\"\"\n",
    "\n",
    "rf_params = {\"n_estimators\": [300],\n",
    "             \"max_depth\": [5],\n",
    "             \"criterion\" :[\"entropy\"],\n",
    "             \"max_features\":[None]     \n",
    "             }\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=2025)\n",
    "\n",
    "# model, params, scoring using f1, 5 folds, full processor\n",
    "rf_grid = GridSearchCV(rf_model, rf_params, scoring='f1_macro', cv=skf, n_jobs=-1)\n",
    "rf_grid.fit(X,y)\n",
    "print(f\"Best RandomForest Model Parameters: {rf_grid.best_params_}\")\n",
    "f1_scores = cross_val_score(rf_grid.best_estimator_,X,y,cv=skf,scoring=\"f1_macro\")\n",
    "print(f1_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5d9d36-9742-4b63-ab45-4474fb3e6315",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "702682fe-723c-4276-8ae5-f43b3fbd52ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Gradient Boost Model Parameters: {'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 50}\n",
      "0.33751405298019127\n"
     ]
    }
   ],
   "source": [
    "# Split data into features and target\n",
    "df = radi.copy()\n",
    "X = df.drop(columns=[\"Transition\"])\n",
    "y = df[\"Transition\"]\n",
    "\n",
    "# Params Definition\n",
    "\"\"\"\n",
    "gb_params = {\"n_estimators\": [100,50,300],\n",
    "             \"max_depth\": [5, 10, 20, None],\n",
    "             \"learning_rate\": [0.1, 0.3,0.01],\n",
    "             \"max_features\":[\"sqrt\",\"log2\", None],\n",
    "             \"loss\": [\"log_loss\", \"exponential\"]\n",
    "             }\n",
    "             \"100\"\n",
    "             \"5\"\n",
    "             \"0.1\n",
    "             \"sqrt\"\n",
    "             \"log_loss\"\n",
    "\"\"\"\n",
    "\n",
    "gb_params = {\"n_estimators\": [50],\n",
    "             \"max_depth\": [5],\n",
    "             \"learning_rate\": [0.1],\n",
    "             \"max_features\":[\"sqrt\"],\n",
    "             \"loss\": [\"log_loss\"]\n",
    "             }\n",
    "gb_model = GradientBoostingClassifier(random_state=2025)\n",
    "\n",
    "# model, params, scoring using f1, 5 folds, full processor\n",
    "gb_grid = GridSearchCV(gb_model, gb_params, scoring='f1_macro', cv=skf, n_jobs=-1)\n",
    "gb_grid.fit(X,y)\n",
    "print(f\"Best Gradient Boost Model Parameters: {gb_grid.best_params_}\")\n",
    "f1_scores = cross_val_score(gb_grid.best_estimator_,X,y,cv=skf,scoring=\"f1_macro\")\n",
    "print(f1_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2258b027-c232-4e1a-aa3c-2fb834d90ac3",
   "metadata": {},
   "source": [
    "## XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d41ee7f8-99ca-4ad4-8308-711faa152405",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# model, params, scoring using f1, 5 folds, full processor\u001b[39;00m\n\u001b[1;32m     37\u001b[0m xgb_grid \u001b[38;5;241m=\u001b[39m GridSearchCV(xgb_model, xgb_params, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_macro\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39mskf, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m xgb_grid\u001b[38;5;241m.\u001b[39mfit(X,y_encoded)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest XGB Model Parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mxgb_grid\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m f1_scores \u001b[38;5;241m=\u001b[39m cross_val_score(xgb_grid\u001b[38;5;241m.\u001b[39mbest_estimator_,X,y_encoded,cv\u001b[38;5;241m=\u001b[39mskf,scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_macro\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1014\u001b[0m     )\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1018\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1572\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:964\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    961\u001b[0m         )\n\u001b[1;32m    962\u001b[0m     )\n\u001b[0;32m--> 964\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    965\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    966\u001b[0m         clone(base_estimator),\n\u001b[1;32m    967\u001b[0m         X,\n\u001b[1;32m    968\u001b[0m         y,\n\u001b[1;32m    969\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    970\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    971\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    972\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    973\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    974\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    975\u001b[0m     )\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[1;32m    979\u001b[0m     )\n\u001b[1;32m    980\u001b[0m )\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Split data into features and target\n",
    "df = radi.copy()\n",
    "X = df.drop(columns=[\"Transition\"])\n",
    "y = df[\"Transition\"]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "xgb_params = {\n",
    "    \"n_estimators\": [50,100,200,300],\n",
    "    \"learning_rate\": [0.1,0.01,0.3],\n",
    "    \"max_depth\": [5,6,8,0],\n",
    "    \"eval_metric\":[\"mlogloss\",\"merror\",\"auc\"]\n",
    "\n",
    "    \"50\"\n",
    "    \"0.1\"\n",
    "    \"5\"\n",
    "    \"mlogloss\"\n",
    "    0.3484980887599893\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "xgb_params = {\n",
    "    \"n_estimators\": [300],\n",
    "    \"learning_rate\": [0.1,0.01,0.3],\n",
    "    \"max_depth\": [5],\n",
    "    \"eval_metric\":[\"mlogloss\"]\n",
    "    \n",
    "}\n",
    "\n",
    "xgb_model = XGBClassifier(random_state=2025)\n",
    "\n",
    "# Initialize and fit LabelEncoder on `y` to transform labels into integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# model, params, scoring using f1, 5 folds, full processor\n",
    "xgb_grid = GridSearchCV(xgb_model, xgb_params, scoring='f1_macro', cv=skf, n_jobs=-1)\n",
    "xgb_grid.fit(X,y_encoded)\n",
    "print(f\"Best XGB Model Parameters: {xgb_grid.best_params_}\")\n",
    "f1_scores = cross_val_score(xgb_grid.best_estimator_,X,y_encoded,cv=skf,scoring=\"f1_macro\")\n",
    "print(f1_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d413f663-7a5a-45f9-9392-cb0e3abed130",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22c8e735-fe5f-49f2-bb27-30e507b45246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM Model Parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.30355303699478087\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "df = radi.copy()\n",
    "X = df.drop(columns=[\"Transition\"]) \n",
    "y = df[\"Transition\"]\n",
    "\n",
    "\"\"\"\n",
    "# Define the parameter grid for SVC\n",
    "param_grid = {\n",
    "    'C': [1, 10, 100,1000],              # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf', 'poly','sigmoid','precomputed'],  # Kernel types ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’\n",
    "    'gamma': ['scale', 'auto'],           # Kernel coefficient for 'rbf' and 'poly' kernels\n",
    "}\n",
    "        \"1\"\n",
    "        \"rbf\"\n",
    "        \"scale\"\n",
    "        0.30355303699478087\n",
    "\"\"\"\n",
    "\n",
    "param_grid = {\n",
    "    'C': [1],             \n",
    "    'kernel': ['rbf'], \n",
    "    'gamma': ['scale','auto'],      \n",
    "} \n",
    "\n",
    "# Initialize the SVC model\n",
    "svm_model = SVC(random_state=2025)\n",
    "\n",
    "svm_grid = GridSearchCV(svm_model,param_grid, \n",
    "                           cv=skf, scoring='f1_macro', n_jobs=-1)\n",
    "\n",
    "svm_grid.fit(X, y)\n",
    "print(f\"Best SVM Model Parameters: {svm_grid.best_params_}\")\n",
    "f1_scores = cross_val_score(svm_grid.best_estimator_,X,y,cv=skf,scoring=\"f1_macro\")\n",
    "print(f1_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e95549c-ccba-4c98-92cb-561d364baae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM Model Parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "0.3146322329963119\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "df = radi.copy()\n",
    "X = df.drop(columns=[\"Transition\"])\n",
    "y = df[\"Transition\"]\n",
    "\n",
    "# Define the parameter grid for SVC\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],              # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf', 'poly'],  # Kernel types\n",
    "    'gamma': ['scale', 'auto'],           # Kernel coefficient for 'rbf' and 'poly' kernels\n",
    "}\n",
    "             \n",
    "\n",
    "# Initialize the SVC model\n",
    "svm_model = SVC(random_state=2025)\n",
    "\n",
    "# model, params, scoring using f1, 5 folds, full processor\n",
    "svm_grid = GridSearchCV(svm_model, param_grid, scoring='f1_macro', cv=skf, n_jobs=-1)\n",
    "svm_grid.fit(X,y)\n",
    "print(f\"Best SVM Model Parameters: {svm_grid.best_params_}\")\n",
    "f1_scores = cross_val_score(svm_grid.best_estimator_,X,y,cv=skf,scoring=\"f1_macro\")\n",
    "print(f1_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310db9ef-1d6d-490b-bf85-9e29eeef0567",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "163d2b1a-50d4-4a5c-aee3-66b8d33bd2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3246995866514756\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df = radi.copy()\n",
    "X = df.drop(columns=[\"Transition\"]) \n",
    "y = df[\"Transition\"]\n",
    "\n",
    "meta_model = RandomForestClassifier(random_state=25)\n",
    "\n",
    "#svm_grid.fit(X,y)\n",
    "#gb_grid.fit(X,y)\n",
    "#rf_grid.fit(X,y)\n",
    "\n",
    "estimators = [(\"gb\", gb_grid.best_estimator_), (\"svm\", svm_grid.best_estimator_), (\"rf\", rf_grid.best_estimator_)]\n",
    "st_model = StackingClassifier(estimators=estimators, final_estimator = meta_model,n_jobs=-1) \n",
    "st_model.fit(X,y)\n",
    "f1_scores = cross_val_score(st_model,X,y,cv=skf,scoring=\"f1_macro\")\n",
    "print(f1_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82b9c85-0155-4b27-b113-99b13f759c31",
   "metadata": {},
   "source": [
    "## Max Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c8c0c79-14ed-4b55-bb83-aa483300c35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33832246420128953\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "df = radi.copy()\n",
    "X = df.drop(columns=[\"Transition\"]) \n",
    "y = df[\"Transition\"]\n",
    "\n",
    "estimators = [(\"gb\", gb_grid.best_estimator_), (\"svm\", svm_grid.best_estimator_), (\"rf\", rf_grid.best_estimator_)]\n",
    "vt_model = VotingClassifier(estimators=estimators, voting = 'hard', weights = [2,1,3],n_jobs=-1) \n",
    "vt_model.fit(X,y)\n",
    "f1_scores = cross_val_score(vt_model,X,y,cv=skf,scoring=\"f1_macro\")\n",
    "print(f1_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46ee5db-1e29-4bf6-a633-c1aa353eaffc",
   "metadata": {},
   "source": [
    "## Generating csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f5ef06f-d585-4137-9c63-098fde399089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "test_data = pd.read_csv(\"../prep1/test_processed_prep1.csv\")\n",
    "\n",
    "\n",
    "# Generate predictions using the RandomForest model\n",
    "rf_predictions_test = rf_grid.best_estimator_.predict(test_data)\n",
    "\n",
    "# Generate predictions using the GB model\n",
    "gb_predictions_test = gb_grid.best_estimator_.predict(test_data)\n",
    "\n",
    "xgb_predictions_test = xgb_grid.best_estimator_.predict(test_data)\n",
    "\n",
    "# Generate predictions using the Voting model\n",
    "st_predictions_test = st_model.predict(test_data)\n",
    "\n",
    "# Generate predictions using the Voting model\n",
    "vb_predictions_test = vt_model.predict(test_data)\n",
    "\n",
    "\n",
    "res0 = pd.DataFrame({\n",
    "    'RowId': range(1, len(xgb_predictions_test) + 1),\n",
    "    'Result': xgb_predictions_test \n",
    "})\n",
    "\n",
    "\n",
    "# Store the results in a DataFrame and save to CSV\n",
    "res1 = pd.DataFrame({\n",
    "    'RowId': range(1, len(rf_predictions_test) + 1),\n",
    "    'Result': rf_predictions_test\n",
    "})\n",
    "\n",
    "# Store the results in a DataFrame and save to CSV\n",
    "res2 = pd.DataFrame({\n",
    "    'RowId': range(1, len(gb_predictions_test) + 1),\n",
    "    'Result': gb_predictions_test\n",
    "})\n",
    "\n",
    "res3 = pd.DataFrame({\n",
    "    'RowId': range(1, len(vb_predictions_test) + 1),\n",
    "    'Result': vb_predictions_test\n",
    "})\n",
    "\n",
    "res4 = pd.DataFrame({\n",
    "    'RowId': range(1, len(st_predictions_test) + 1),\n",
    "    'Result': st_predictions_test\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "res0.to_csv('NXGBGrid1.0.csv', index=False)\n",
    "res1.to_csv('NRandomForestGrid1.0.csv', index=False)\n",
    "res2.to_csv('NGradientBoostingGrid1.0.csv', index=False)\n",
    "res3.to_csv('NVoting1.0.csv', index=False)\n",
    "res4.to_csv('NStacking1.0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6eee07-6cc8-4c25-87da-11595ceb18b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
