{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "85d5af3c-b360-40ac-b1ca-b040430bede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import imblearn\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a4957abd-3351-470e-b871-78b5eec613fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 305 entries, 0 to 304\n",
      "Columns: 2162 entries, diagnostics_Image-original_Dimensionality to Transition\n",
      "dtypes: float64(2161), object(1)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "radi = pd.read_csv(\"sbsppdaa24/train_radiomics_hipocamp.csv\")\n",
    "\n",
    "# Drop unique identifier columns\n",
    "radi.drop(columns=[\"Mask\", \"ID\", \"Image\"], inplace=True)\n",
    "\n",
    "# Drop non-numeric columns except for 'Transition'\n",
    "columns_to_drop = [col for col in radi.columns if radi[col].dtype == 'object' and col != 'Transition']\n",
    "radi.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Apply MinMax scaling to columns\n",
    "float_cols = radi.select_dtypes(include=['float','int']).columns\n",
    "scaler = MinMaxScaler()\n",
    "radi[float_cols] = scaler.fit_transform(radi[float_cols])\n",
    "\n",
    "# Intantiate Report\n",
    "classification_reports = {}\n",
    "\n",
    "# Check final dataset\n",
    "radi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "764516de-dd90-4e8f-8d0a-e508e0b9dfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV,StratifiedKFold,cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "# Estado vai ser comum para todos os modelos, \n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2025)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e07871-dd1b-489a-aae5-ee509069e8f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27898429-69f0-4ccd-a29f-e9005376da27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Bagging Model Parameters: {'n_estimators': 800}\n",
      "Bagging Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       AD-AD       0.50      0.36      0.42        14\n",
      "       CN-CN       0.51      0.69      0.59        26\n",
      "      CN-MCI       0.00      0.00      0.00         1\n",
      "      MCI-AD       0.32      0.43      0.36        14\n",
      "     MCI-MCI       0.23      0.14      0.17        22\n",
      "\n",
      "    accuracy                           0.42        77\n",
      "   macro avg       0.31      0.32      0.31        77\n",
      "weighted avg       0.39      0.42      0.39        77\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Split data into features and target\n",
    "df = radi.copy()\n",
    "X = df.drop(columns=[\"Transition\"])\n",
    "y = df[\"Transition\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2025)\n",
    "\n",
    "bagging_params = {\"n_estimators\": [100, 500, 800, 1000]}\n",
    "bagging_model = BaggingClassifier(random_state=2025)\n",
    "bagging_grid = GridSearchCV(bagging_model, bagging_params, scoring='f1_macro', cv=skf, n_jobs=-1)\n",
    "bagging_grid.fit(X_train, y_train)\n",
    "y_pred_bagging = bagging_grid.best_estimator_.predict(X_test)\n",
    "classification_reports[\"Bagging\"] = classification_report(y_test, y_pred_bagging, output_dict=True)\n",
    "print(f\"Best Bagging Model Parameters: {bagging_grid.best_params_}\")\n",
    "print(f\"Bagging Classification Report:\\n\", classification_report(y_test, y_pred_bagging))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18a4150-9b94-4422-b7e4-cf77d7f24380",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18d2b434-43af-4c58-9a20-07296e14e797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RandomForest Model Parameters: {'criterion': 'gini', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 500}\n",
      "RandomForest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       AD-AD       0.50      0.29      0.36        14\n",
      "       CN-CN       0.53      0.73      0.61        26\n",
      "      CN-MCI       0.00      0.00      0.00         1\n",
      "      MCI-AD       0.28      0.36      0.31        14\n",
      "     MCI-MCI       0.33      0.23      0.27        22\n",
      "\n",
      "    accuracy                           0.43        77\n",
      "   macro avg       0.33      0.32      0.31        77\n",
      "weighted avg       0.41      0.43      0.41        77\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest RandomForest Model Parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrf_grid\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandomForest Classification Report:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, classification_report(y_test, y_pred_rf))\n\u001b[0;32m---> 27\u001b[0m rf_grid\u001b[38;5;241m.\u001b[39mfit(X,y)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest RandomForest Model Parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrf_grid\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m f1_scores \u001b[38;5;241m=\u001b[39m cross_val_score(rf_grid\u001b[38;5;241m.\u001b[39mbest_estimator_,X,y,cv\u001b[38;5;241m=\u001b[39mskf,scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_macro\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1014\u001b[0m     )\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1018\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1572\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:964\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    961\u001b[0m         )\n\u001b[1;32m    962\u001b[0m     )\n\u001b[0;32m--> 964\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    965\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    966\u001b[0m         clone(base_estimator),\n\u001b[1;32m    967\u001b[0m         X,\n\u001b[1;32m    968\u001b[0m         y,\n\u001b[1;32m    969\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    970\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    971\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    972\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    973\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    974\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    975\u001b[0m     )\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[1;32m    979\u001b[0m     )\n\u001b[1;32m    980\u001b[0m )\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Split data into features and target\n",
    "df = radi.copy()\n",
    "X = df.drop(columns=[\"Transition\"])\n",
    "y = df[\"Transition\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2025)\n",
    "\n",
    "# Params Definition\n",
    "rf_params = {\"n_estimators\": [100,300,500],\n",
    "             \"max_depth\": [5, 10, 20, None],\n",
    "             \"criterion\" :[\"gini\",\"entropy\"],\n",
    "             \"min_samples_split\":[2,5],\n",
    "             \"max_features\":[\"sqrt\",\"log2\", None]     \n",
    "             }\n",
    "rf_model = RandomForestClassifier(random_state=2025)\n",
    "\n",
    "# model, params, scoring using f1, 5 folds, full processor\n",
    "rf_grid = GridSearchCV(rf_model, rf_params, scoring='f1_macro', cv=skf, n_jobs=-1)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_grid.best_estimator_.predict(X_test)\n",
    "classification_reports[\"RandomForest\"] = classification_report(y_test, y_pred_rf, output_dict=True)\n",
    "print(f\"Best RandomForest Model Parameters: {rf_grid.best_params_}\")\n",
    "print(f\"RandomForest Classification Report:\\n\", classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b65dbbe1-66b1-467a-bc3f-dd06e38be801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RandomForest Model Parameters: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 500}\n",
      "0.34220925387475404\n"
     ]
    }
   ],
   "source": [
    "# Split data into features and target\n",
    "df = radi.copy()\n",
    "X = df.drop(columns=[\"Transition\"])\n",
    "y = df[\"Transition\"]\n",
    "\n",
    "# Params Definition\n",
    "rf_params = {\"n_estimators\": [100,300,500],\n",
    "             \"max_depth\": [5, 10, 20, None],\n",
    "             \"criterion\" :[\"gini\",\"entropy\"],\n",
    "             \"min_samples_split\":[2,5],\n",
    "             \"max_features\":[\"sqrt\",\"log2\", None]     \n",
    "             }\n",
    "rf_model = RandomForestClassifier(random_state=2025)\n",
    "\n",
    "# model, params, scoring using f1, 5 folds, full processor\n",
    "rf_grid = GridSearchCV(rf_model, rf_params, scoring='f1_macro', cv=skf, n_jobs=-1)\n",
    "rf_grid.fit(X,y)\n",
    "print(f\"Best RandomForest Model Parameters: {rf_grid.best_params_}\")\n",
    "f1_scores = cross_val_score(rf_grid.best_estimator_,X,y,cv=skf,scoring=\"f1_macro\")\n",
    "print(f1_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5d9d36-9742-4b63-ab45-4474fb3e6315",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c59c35e6-1870-49f1-a770-a091264f5fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best GradientBoosting Model Parameters: {'learning_rate': 0.3, 'n_estimators': 500}\n",
      "GradientBoosting Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       AD-AD       0.40      0.29      0.33        14\n",
      "       CN-CN       0.59      0.62      0.60        26\n",
      "      CN-MCI       0.00      0.00      0.00         1\n",
      "      MCI-AD       0.44      0.50      0.47        14\n",
      "     MCI-MCI       0.37      0.32      0.34        22\n",
      "\n",
      "    accuracy                           0.44        77\n",
      "   macro avg       0.36      0.34      0.35        77\n",
      "weighted avg       0.46      0.44      0.45        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split data into features and target\n",
    "df = radi.copy()\n",
    "X = df.drop(columns=[\"Transition\"]) \n",
    "y = df[\"Transition\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2025)\n",
    "\n",
    "# Params Definition\n",
    "gb_params = {\"n_estimators\": [500, 600, 1000], \"learning_rate\": [0.1, 0.3,0.01]}\n",
    "gb_model = GradientBoostingClassifier(random_state=2025)\n",
    "\n",
    "# model, params, scoring using f1, 5 folds, full processor\n",
    "gb_grid = GridSearchCV(gb_model, gb_params, scoring='f1_macro',cv=skf, n_jobs=-1)\n",
    "gb_grid.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gb = gb_grid.best_estimator_.predict(X_test)\n",
    "classification_reports[\"GradientBoosting\"] = classification_report(y_test, y_pred_gb, output_dict=True)\n",
    "print(f\"Best GradientBoosting Model Parameters: {gb_grid.best_params_}\")\n",
    "print(f\"GradientBoosting Classification Report:\\n\", classification_report(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "702682fe-723c-4276-8ae5-f43b3fbd52ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Gradient Boost Model Parameters: {'learning_rate': 0.3, 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 50}\n",
      "0.3488054635401693\n"
     ]
    }
   ],
   "source": [
    "# Split data into features and target\n",
    "df = radi.copy()\n",
    "X = df.drop(columns=[\"Transition\"])\n",
    "y = df[\"Transition\"]\n",
    "\n",
    "# Params Definition\n",
    "gb_params = {\"n_estimators\": [100,50,300],\n",
    "             \"max_depth\": [5, 10, None],\n",
    "             \"learning_rate\": [0.1, 0.3,0.01],\n",
    "             \"max_features\":[\"sqrt\",\"log2\", None]     \n",
    "             }\n",
    "gb_model = GradientBoostingClassifier(random_state=2025)\n",
    "\n",
    "# model, params, scoring using f1, 5 folds, full processor\n",
    "gb_grid = GridSearchCV(gb_model, gb_params, scoring='f1_macro', cv=skf, n_jobs=-1)\n",
    "gb_grid.fit(X,y)\n",
    "print(f\"Best Gradient Boost Model Parameters: {gb_grid.best_params_}\")\n",
    "f1_scores = cross_val_score(gb_grid.best_estimator_,X,y,cv=skf,scoring=\"f1_macro\")\n",
    "print(f1_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2258b027-c232-4e1a-aa3c-2fb834d90ac3",
   "metadata": {},
   "source": [
    "## XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1253b0a5-b399-45f0-8784-57923a8b6622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost Model Parameters: {'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "XGBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.43      0.50        14\n",
      "           1       0.50      0.73      0.59        26\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.29      0.29      0.29        14\n",
      "           4       0.27      0.18      0.22        22\n",
      "\n",
      "    accuracy                           0.43        77\n",
      "   macro avg       0.33      0.33      0.32        77\n",
      "weighted avg       0.41      0.43      0.41        77\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Copy the dataframe and apply label encoding to the target variable\n",
    "df = radi.copy()\n",
    "label_encoder = LabelEncoder()\n",
    "df['Transition'] = label_encoder.fit_transform(df['Transition'])\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=[\"Transition\"])\n",
    "y = df[\"Transition\"]\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2025)\n",
    "\n",
    "# Define XGBoost hyperparameters and model with a multi-class objective and compatible eval_metric\n",
    "xgb_params = {\n",
    "    \"n_estimators\": [500,800,600],\n",
    "    \"learning_rate\": [0.1,0.3],\n",
    "    \"max_depth\": [5,6,8,20],\n",
    "    \n",
    "}\n",
    "\n",
    "xgb_model = XGBClassifier(eval_metric='mlogloss',random_state=2025)\n",
    "\n",
    "# Run GridSearchCV to find the best parameters\n",
    "xgb_grid = GridSearchCV(xgb_model, xgb_params, scoring='f1_macro', cv=skf, n_jobs=-1)\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_xgb = xgb_grid.best_estimator_.predict(X_test)\n",
    "classification_reports[\"XGBoost\"] = classification_report(y_test, y_pred_xgb, output_dict=True)\n",
    "print(f\"Best XGBoost Model Parameters: {xgb_grid.best_params_}\")\n",
    "print(f\"XGBoost Classification Report:\\n\", classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d41ee7f8-99ca-4ad4-8308-711faa152405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGB Model Parameters: {'eval_metric': 'mlogloss', 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.3442090086904702\n"
     ]
    }
   ],
   "source": [
    "# Split data into features and target\n",
    "df = radi.copy()\n",
    "X = df.drop(columns=[\"Transition\"])\n",
    "y = df[\"Transition\"]\n",
    "\n",
    "xgb_params = {\n",
    "    \"n_estimators\": [100,200,300],\n",
    "    \"learning_rate\": [0.1,0.3],\n",
    "    \"max_depth\": [5,6,8,0],\n",
    "    \"eval_metric\":[\"mlogloss\",\"merror\",\"auc\"]\n",
    "    \n",
    "}\n",
    "\n",
    "xgb_model = XGBClassifier(random_state=2025)\n",
    "\n",
    "# Initialize and fit LabelEncoder on `y` to transform labels into integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# model, params, scoring using f1, 5 folds, full processor\n",
    "xgb_grid = GridSearchCV(xgb_model, xgb_params, scoring='f1_macro', cv=skf, n_jobs=-1)\n",
    "xgb_grid.fit(X,y_encoded)\n",
    "print(f\"Best XGB Model Parameters: {xgb_grid.best_params_}\")\n",
    "f1_scores = cross_val_score(xgb_grid.best_estimator_,X,y_encoded,cv=skf,scoring=\"f1_macro\")\n",
    "print(f1_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5b00fb-952b-4b6c-9f12-fed0d6063ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=[\"Transition\"])\n",
    "y = df[\"Transition\"]\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2025)\n",
    "\n",
    "# Define XGBoost hyperparameters and model with a multi-class objective and compatible eval_metric\n",
    "xgb_params = {\n",
    "    \"n_estimators\": [500,1000],\n",
    "    \"learning_rate\": [0.1,0.01],\n",
    "    \"max_depth\": [5,20,0],\n",
    "    \n",
    "}\n",
    "\n",
    "xgb_model = XGBClassifier(objective='multi:softmax',random_state=2025)\n",
    "\n",
    "# Run GridSearchCV to find the best parameters\n",
    "xgb_grid = GridSearchCV(xgb_model, xgb_params, scoring='f1_macro', cv=skf, n_jobs=-1)\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_xgb = xgb_grid.best_estimator_.predict(X_test)\n",
    "classification_reports[\"XGBoost\"] = classification_report(y_test, y_pred_xgb, output_dict=True)\n",
    "print(f\"Best XGBoost Model Parameters: {xgb_grid.best_params_}\")\n",
    "print(f\"XGBoost Classification Report:\\n\", classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d413f663-7a5a-45f9-9392-cb0e3abed130",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22c8e735-fe5f-49f2-bb27-30e507b45246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best SVM Model Parameters: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       AD-AD       0.62      0.36      0.45        14\n",
      "       CN-CN       0.51      0.85      0.64        26\n",
      "      CN-MCI       0.00      0.00      0.00         1\n",
      "      MCI-AD       0.33      0.43      0.38        14\n",
      "     MCI-MCI       0.38      0.14      0.20        22\n",
      "\n",
      "    accuracy                           0.47        77\n",
      "   macro avg       0.37      0.35      0.33        77\n",
      "weighted avg       0.45      0.47      0.42        77\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "df = radi.copy()\n",
    "X = df.drop(columns=[\"Transition\"]) \n",
    "y = df[\"Transition\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2025)\n",
    "\n",
    "# Define the parameter grid for SVC\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],              # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf', 'poly'],  # Kernel types\n",
    "    'gamma': ['scale', 'auto'],           # Kernel coefficient for 'rbf' and 'poly' kernels\n",
    "}\n",
    "\n",
    "# Initialize the SVC model\n",
    "svm_model = SVC(random_state=2025)\n",
    "\n",
    "svm_grid = GridSearchCV(estimator=svm_model, param_grid=param_grid, \n",
    "                           cv=5, scoring='f1_macro', verbose=1, n_jobs=-1)\n",
    "\n",
    "svm_grid.fit(X_train, y_train)\n",
    "y_pred_svm = svm_grid.best_estimator_.predict(X_test)\n",
    "classification_reports[\"SVM\"] = classification_report(y_test, y_pred_svm, output_dict=True)\n",
    "print(f\"Best SVM Model Parameters: {svm_grid.best_params_}\")\n",
    "print(f\"SVM Classification Report:\\n\", classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e95549c-ccba-4c98-92cb-561d364baae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM Model Parameters: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.3155425216149884\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "df = radi.copy()\n",
    "X = df.drop(columns=[\"Transition\"])\n",
    "y = df[\"Transition\"]\n",
    "\n",
    "# Define the parameter grid for SVC\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],              # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf', 'poly'],  # Kernel types\n",
    "    'gamma': ['scale', 'auto'],           # Kernel coefficient for 'rbf' and 'poly' kernels\n",
    "}\n",
    "             \n",
    "\n",
    "# Initialize the SVC model\n",
    "svm_model = SVC(random_state=2025)\n",
    "\n",
    "# model, params, scoring using f1, 5 folds, full processor\n",
    "svm_grid = GridSearchCV(svm_model, param_grid, scoring='f1_macro', cv=skf, n_jobs=-1)\n",
    "svm_grid.fit(X,y)\n",
    "print(f\"Best SVM Model Parameters: {svm_grid.best_params_}\")\n",
    "f1_scores = cross_val_score(svm_grid.best_estimator_,X,y,cv=skf,scoring=\"f1_macro\")\n",
    "print(f1_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310db9ef-1d6d-490b-bf85-9e29eeef0567",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "163d2b1a-50d4-4a5c-aee3-66b8d33bd2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       AD-AD       0.44      0.29      0.35        14\n",
      "       CN-CN       0.56      0.77      0.65        26\n",
      "      CN-MCI       0.00      0.00      0.00         1\n",
      "      MCI-AD       0.31      0.36      0.33        14\n",
      "     MCI-MCI       0.31      0.23      0.26        22\n",
      "\n",
      "    accuracy                           0.44        77\n",
      "   macro avg       0.33      0.33      0.32        77\n",
      "weighted avg       0.41      0.44      0.42        77\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df = radi.copy()\n",
    "X = df.drop(columns=[\"Transition\"]) \n",
    "y = df[\"Transition\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2025)\n",
    "\n",
    "meta_model = RandomForestClassifier(random_state=25)\n",
    "\n",
    "estimators = [(\"gb\", gb_grid.best_estimator_), (\"svm\", svm_grid.best_estimator_), (\"rf\", rf_grid.best_estimator_)]\n",
    "st_model = StackingClassifier(estimators=estimators, final_estimator = meta_model) \n",
    "st_model.fit(X_train, y_train)\n",
    "st_predictions = st_model.predict(X_test)\n",
    "classification_reports[\"Stacking\"] = classification_report(y_test, st_predictions, output_dict=True)\n",
    "print(f\"Stacking Classification Report:\\n\", classification_report(y_test, st_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82b9c85-0155-4b27-b113-99b13f759c31",
   "metadata": {},
   "source": [
    "## Max Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c8c0c79-14ed-4b55-bb83-aa483300c35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       AD-AD       0.20      0.14      0.17        14\n",
      "       CN-CN       0.53      0.69      0.60        26\n",
      "      CN-MCI       0.00      0.00      0.00         1\n",
      "      MCI-AD       0.32      0.43      0.36        14\n",
      "     MCI-MCI       0.36      0.23      0.28        22\n",
      "\n",
      "    accuracy                           0.40        77\n",
      "   macro avg       0.28      0.30      0.28        77\n",
      "weighted avg       0.37      0.40      0.38        77\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/nunorodrigues/miniconda3/envs/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "df = radi.copy()\n",
    "X = df.drop(columns=[\"Transition\"]) \n",
    "y = df[\"Transition\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2025)\n",
    "\n",
    "estimators = [(\"gb\", gb_grid.best_estimator_), (\"svm\", svm_grid.best_estimator_), (\"rf\", rf_grid.best_estimator_)]\n",
    "vt_model = VotingClassifier(estimators=estimators, voting = 'hard', weights = [3,2,1]) \n",
    "vt_model.fit(X_train, y_train)\n",
    "vt_predictions = vt_model.predict(X_test)\n",
    "classification_reports[\"Voting\"] = classification_report(y_test, vt_predictions, output_dict=True)\n",
    "print(f\"Voting Classification Report:\\n\", classification_report(y_test, st_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582cf1f4-e743-42b9-822f-b267c01e39ef",
   "metadata": {},
   "source": [
    "## Ver Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31dedfa6-8434-48b1-97ee-1c9720974b5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'%macro avg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming f1_scores is already defined\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m f1_scores \u001b[38;5;241m=\u001b[39m {model: report[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mmacro avg\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1-score\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m model, report \u001b[38;5;129;01min\u001b[39;00m classification_reports\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Plotting\u001b[39;00m\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n",
      "\u001b[0;31mKeyError\u001b[0m: '%macro avg'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming f1_scores is already defined\n",
    "f1_scores = {model: report[\"macro avg\"][\"f1-score\"] for model, report in classification_reports.items()}\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "# F1 Score Graph\n",
    "plt.subplot(1, 2, 1)\n",
    "bars = plt.bar(f1_scores.keys(), f1_scores.values(), color='skyblue')\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.title(\"Model Comparison - F1 Scores\")\n",
    "plt.ylim(0, 0.6)\n",
    "\n",
    "# Display values on top of each bar\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.01, f'{yval:.2f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61ce0b20-6526-4040-96a2-adbffb3aaf75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies = {model: report[\"accuracy\"] for model, report in classification_reports.items()}\n",
    "\n",
    "# Accuracy Graph\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.subplot(1, 2, 2)\n",
    "bars = plt.bar(accuracies.keys(), accuracies.values(), color='salmon')\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Model Comparison - Accuracy\")\n",
    "plt.ylim(0, 0.6)\n",
    "\n",
    "\n",
    "# Display values on top of each bar\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.01, f'{yval:.2f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46ee5db-1e29-4bf6-a633-c1aa353eaffc",
   "metadata": {},
   "source": [
    "## Generating csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5ef06f-d585-4137-9c63-098fde399089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the test dataset\n",
    "test_data = pd.read_csv(\"sbsppdaa24/test_radiomics_hipocamp.csv\")\n",
    "\n",
    "# Apply the same preprocessing as in the training phase\n",
    "# Drop unique identifier columns\n",
    "test_data.drop(columns=[\"Mask\", \"ID\", \"Image\"], inplace=True)\n",
    "\n",
    "# Ensure 'columns_to_drop' is available for test data\n",
    "# If you haven't redefined this variable, you need to redo this step for the test set.\n",
    "# Use the same method to identify non-numeric columns for dropping\n",
    "non_numeric_columns = [col for col in test_data.columns if test_data[col].dtype == 'object']\n",
    "test_data.drop(columns=non_numeric_columns, inplace=True)\n",
    "\n",
    "# Apply the same MinMaxScaler that was fit on the training data\n",
    "test_data[float_cols] = scaler.transform(test_data[float_cols])  # Correctly reference columns in test_data\n",
    "\n",
    "# Generate predictions using the Bagging model\n",
    "bg_predictions_test = bagging_grid.best_estimator_.predict(test_data)\n",
    "\n",
    "# Generate predictions using the RandomForest model\n",
    "rf_predictions_test = rf_grid.best_estimator_.predict(test_data)\n",
    "\n",
    "# Generate predictions using the GB model\n",
    "gb_predictions_test = gb_grid.best_estimator_.predict(test_data)\n",
    "\n",
    "# Generate predictions using the Voting model\n",
    "vb_predictions_test = vt_model.predict(test_data)\n",
    "\n",
    "\n",
    "res0 = pd.DataFrame({\n",
    "    'RowId': range(1, len(bg_predictions_test) + 1),\n",
    "    'Result': bg_predictions_test \n",
    "})\n",
    "\n",
    "\n",
    "# Store the results in a DataFrame and save to CSV\n",
    "res1 = pd.DataFrame({\n",
    "    'RowId': range(1, len(rf_predictions_test) + 1),\n",
    "    'Result': rf_predictions_test\n",
    "})\n",
    "\n",
    "# Store the results in a DataFrame and save to CSV\n",
    "res2 = pd.DataFrame({\n",
    "    'RowId': range(1, len(gb_predictions_test) + 1),\n",
    "    'Result': gb_predictions_test\n",
    "})\n",
    "\n",
    "res3 = pd.DataFrame({\n",
    "    'RowId': range(1, len(vb_predictions_test) + 1),\n",
    "    'Result': vb_predictions_test\n",
    "})\n",
    "\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "res0.to_csv('BagginGrid1.0.csv', index=False)\n",
    "res1.to_csv('RandomForestGrid1.0.csv', index=False)\n",
    "res2.to_csv('GradientBoostingGrid1.0.csv', index=False)\n",
    "res3.to_csv('Voting1.0.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3748da0e-e79f-46ee-b9e1-4e483d5efb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the test dataset\n",
    "test_data = pd.read_csv(\"sbsppdaa24/test_radiomics_hipocamp.csv\")\n",
    "\n",
    "# Apply the same preprocessing as in the training phase\n",
    "# Drop unique identifier columns\n",
    "test_data.drop(columns=[\"Mask\", \"ID\", \"Image\"], inplace=True)\n",
    "\n",
    "# Ensure 'columns_to_drop' is available for test data\n",
    "# If you haven't redefined this variable, you need to redo this step for the test set.\n",
    "# Use the same method to identify non-numeric columns for dropping\n",
    "non_numeric_columns = [col for col in test_data.columns if test_data[col].dtype == 'object']\n",
    "test_data.drop(columns=non_numeric_columns, inplace=True)\n",
    "\n",
    "# Apply the same MinMaxScaler that was fit on the training data\n",
    "test_data[float_cols] = scaler.transform(test_data[float_cols])  # Correctly reference columns in test_data\n",
    "# Generate predictions using the RandomForest model\n",
    "rf_predictions_test = rf_grid.best_estimator_.predict(test_data)\n",
    "\n",
    "res1 = pd.DataFrame({\n",
    "    'RowId': range(1, len(rf_predictions_test) + 1),\n",
    "    'Result': rf_predictions_test\n",
    "})\n",
    "\n",
    "res1.to_csv('RandomForestGrid1.1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "003c1ae7-b8b4-43fa-9ab7-49d04923c1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the test dataset\n",
    "test_data = pd.read_csv(\"sbsppdaa24/test_radiomics_hipocamp.csv\")\n",
    "\n",
    "# Apply the same preprocessing as in the training phase\n",
    "# Drop unique identifier columns\n",
    "test_data.drop(columns=[\"Mask\", \"ID\", \"Image\"], inplace=True)\n",
    "\n",
    "# Ensure 'columns_to_drop' is available for test data\n",
    "# If you haven't redefined this variable, you need to redo this step for the test set.\n",
    "# Use the same method to identify non-numeric columns for dropping\n",
    "non_numeric_columns = [col for col in test_data.columns if test_data[col].dtype == 'object']\n",
    "test_data.drop(columns=non_numeric_columns, inplace=True)\n",
    "\n",
    "# Apply the same MinMaxScaler that was fit on the training data\n",
    "test_data[float_cols] = scaler.transform(test_data[float_cols])  # Correctly reference columns in test_data\n",
    "# Generate predictions using the RandomForest model\n",
    "gb_predictions_test = gb_grid.best_estimator_.predict(test_data)\n",
    "\n",
    "res2 = pd.DataFrame({\n",
    "    'RowId': range(1, len(gb_predictions_test) + 1),\n",
    "    'Result': gb_predictions_test\n",
    "})\n",
    "\n",
    "res2.to_csv('GradientBoostingGrid1.1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a7c534ce-7933-480b-9de5-53ebda772cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the test dataset\n",
    "test_data = pd.read_csv(\"sbsppdaa24/test_radiomics_hipocamp.csv\")\n",
    "\n",
    "# Apply the same preprocessing as in the training phase\n",
    "# Drop unique identifier columns\n",
    "test_data.drop(columns=[\"Mask\", \"ID\", \"Image\"], inplace=True)\n",
    "\n",
    "# Ensure 'columns_to_drop' is available for test data\n",
    "# If you haven't redefined this variable, you need to redo this step for the test set.\n",
    "# Use the same method to identify non-numeric columns for dropping\n",
    "non_numeric_columns = [col for col in test_data.columns if test_data[col].dtype == 'object']\n",
    "test_data.drop(columns=non_numeric_columns, inplace=True)\n",
    "\n",
    "# Apply the same MinMaxScaler that was fit on the training data\n",
    "test_data[float_cols] = scaler.transform(test_data[float_cols])  # Correctly reference columns in test_data\n",
    "# Generate predictions using the RandomForest model\n",
    "\n",
    "\n",
    "df = radi.copy()\n",
    "X = df.drop(columns=[\"Transition\"]) \n",
    "y = df[\"Transition\"]\n",
    "\n",
    "st_model.fit(X,y)\n",
    "st_predictions_test = st_model.predict(test_data)\n",
    "\n",
    "res3 = pd.DataFrame({\n",
    "    'RowId': range(1, len(st_predictions_test) + 1),\n",
    "    'Result': st_predictions_test\n",
    "})\n",
    "\n",
    "res3.to_csv('Stacking3ModeloFullData1.1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c98902c6-c85d-409f-917e-756e62be504c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 35\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Initialize and train the XGBClassifier\u001b[39;00m\n\u001b[1;32m     31\u001b[0m xgbf_model \u001b[38;5;241m=\u001b[39m XGBClassifier(\n\u001b[1;32m     32\u001b[0m     eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m,\n\u001b[1;32m     33\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2025\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     34\u001b[0m )\n\u001b[0;32m---> 35\u001b[0m xgbf_model\u001b[38;5;241m.\u001b[39mfit(X, y_encoded)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Generate predictions for the test data\u001b[39;00m\n\u001b[1;32m     38\u001b[0m xgbf_predictions_test_encoded \u001b[38;5;241m=\u001b[39m xgbf_model\u001b[38;5;241m.\u001b[39mpredict(test_data)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/xgboost/sklearn.py:1531\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1511\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[1;32m   1512\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1513\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1514\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1528\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1529\u001b[0m )\n\u001b[0;32m-> 1531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[1;32m   1532\u001b[0m     params,\n\u001b[1;32m   1533\u001b[0m     train_dmatrix,\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_boosting_rounds(),\n\u001b[1;32m   1535\u001b[0m     evals\u001b[38;5;241m=\u001b[39mevals,\n\u001b[1;32m   1536\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_stopping_rounds,\n\u001b[1;32m   1537\u001b[0m     evals_result\u001b[38;5;241m=\u001b[39mevals_result,\n\u001b[1;32m   1538\u001b[0m     obj\u001b[38;5;241m=\u001b[39mobj,\n\u001b[1;32m   1539\u001b[0m     custom_metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[1;32m   1540\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m   1541\u001b[0m     xgb_model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m   1542\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[1;32m   1543\u001b[0m )\n\u001b[1;32m   1545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, iteration\u001b[38;5;241m=\u001b[39mi, fobj\u001b[38;5;241m=\u001b[39mobj)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/xgboost/core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2100\u001b[0m     _check_call(\n\u001b[0;32m-> 2101\u001b[0m         _LIB\u001b[38;5;241m.\u001b[39mXGBoosterUpdateOneIter(\n\u001b[1;32m   2102\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, ctypes\u001b[38;5;241m.\u001b[39mc_int(iteration), dtrain\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   2103\u001b[0m         )\n\u001b[1;32m   2104\u001b[0m     )\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load the test dataset\n",
    "test_data = pd.read_csv(\"sbsppdaa24/test_radiomics_hipocamp.csv\")\n",
    "\n",
    "# Apply the same preprocessing as in the training phase\n",
    "# Drop unique identifier columns\n",
    "test_data.drop(columns=[\"Mask\", \"ID\", \"Image\"], inplace=True)\n",
    "\n",
    "# Ensure 'columns_to_drop' is available for test data\n",
    "# If you haven't redefined this variable, you need to redo this step for the test set.\n",
    "# Use the same method to identify non-numeric columns for dropping\n",
    "non_numeric_columns = [col for col in test_data.columns if test_data[col].dtype == 'object']\n",
    "test_data.drop(columns=non_numeric_columns, inplace=True)\n",
    "\n",
    "# Apply the same MinMaxScaler that was fit on the training data\n",
    "test_data[float_cols] = scaler.transform(test_data[float_cols])  # Correctly reference columns in test_data\n",
    "\n",
    "# Encode target labels\n",
    "df = radi.copy()\n",
    "X = df.drop(columns=[\"Transition\"]) \n",
    "y = df[\"Transition\"]\n",
    "\n",
    "# Initialize and fit LabelEncoder on `y` to transform labels into integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Initialize and train the XGBClassifier 'eval_metric': 'mlogloss', 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100\n",
    "xgbf_model = XGBClassifier(\n",
    "    eval_metric='mlogloss', learning_rate=0.1, max_depth=6, n_estimators=100,\n",
    "    random_state=2025, n_jobs=-1\n",
    ")\n",
    "xgbf_model.fit(X, y_encoded)\n",
    "\n",
    "# Generate predictions for the test data\n",
    "\n",
    "xgbf_predictions_test_encoded = xgbf_model.predict(test_data)\n",
    "\n",
    "# Decode predictions back to original string labels\n",
    "xgbf_predictions_test = label_encoder.inverse_transform(xgbf_predictions_test_encoded)\n",
    "\n",
    "# Save predictions in a CSV file with original labels\n",
    "res3 = pd.DataFrame({\n",
    "    'RowId': range(1, len(xgbf_predictions_test) + 1),\n",
    "    'Result': xgbf_predictions_test\n",
    "})\n",
    "\n",
    "res3.to_csv('XGBFullData1.1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a071b7-facf-46e8-a0da-35bbe773e000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
